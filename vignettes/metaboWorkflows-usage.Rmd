---
title: "metaboWorkflows"
subtitle: "`r paste0('v',packageVersion('metaboWorkflows'))`"
author: "Jasen Finch"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  prettydoc::html_pretty:
    toc: true
    highlight: github
    theme: tactile
vignette: >
  %\VignetteIndexEntry{metaboWorkflows-usage}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Introduction

Metabolomics encompasses a wide range of techniques that includes both fingerprinting and profiling.
These require the application of a diverse range of processing algorithms, pre-treatment strategies and statistical analyses to extract biological information.
In turn, these often require numerous software packages, each providing just a small part of the metabolomics workflow.
However, these can be wrapped together to provide metabolomics analysis pipelines.

The aim of *metaboWorkflows* is to provide a high-level framework for metabolomics analysis pipelines that is simple to use for routine analyses, encompassing a wide range of metabolomics techniques.
*metaboWorkflows* breaks metabolomics analysis into three main sections:

* processing
* analysis
* annotation

Processing encompasses the signal processing aspect where an intensity matrix is constructed using algorithms specific to the metabolomics technique. 
Analysis encompasses the statistical analysis aspects where the data is analysed in the context of the biological question. This can include data pre-treatment, classification and feature selection steps.
Annotation can include assignment of molecular formulas or metabolite names to features extracted during processing.

These sections don't necessarily need to occur in that particular order for a given workflow. 
For instance, annotation could occur prior to certain analysis steps to make the results more interpretable in a biological context.

This document will first discuss how to use metaboWorkflows followed by more detailed discussion of each of the workflows that are available in the package.

## Basic Usage

The [*hrm*](https://github.com/jasenfinch/hrm) package provides utility for easy loading of the packages that can be required whilst using *metaboWorklows*.
This can be installed by running:

```{r hrm, eval=FALSE}
devtools::install_github('jasenfinch/hrm')
```

The packages can then easily be loaded using:

```{r hrmAttach,eval=FALSE}
hrm::hrmAttach()
```

Otherwise run:

```{r libraryLoad,message=FALSE}
library(metaboWorkflows)
library(metaboData)
library(binneR)
```

There are three main functions that are used within the *metaboWorkflows* package:

* `workflowParameters()` - allows the selection of the workflow to use and returns the relevant default parameters.
* `workflow()` - execute the workflow for the given parameters. 
* `restartWorkflow()` - used to restart a workflow after a check point stoppage or failure.

The available workflows within the package can be found by running:

```{r availbleWorkflows,message=TRUE}
availableWorkflows()
```

These workflows include:

* `FIE-HRMS fingerprinting` - Flow infusion electrospray high resolution mass spectrometry fingerprinting
* `NSI-HRMS fingerprinting` - Nanospray ionisation high resolution mass spectrometry fingerprinting
* `RP-LC-HRMS profiling` - Reverse phase liquid chromatography high resolution mass spectrometry profiling
* `NP-LC-HRMS profiling` - Normal phase liquid chromatography high resolution mass spectrometry profiling
* `GC-MS profiling deconvolution` - Gas chromatography mass spectrometry profiling using deconvolution

*metaboWorkflows* provides methods for the modification of parameters and extraction of results for the objects that are returned by these functions. However, because *metaboWorkflows* encompasses a number of different analysis packages, the user is referred to the documentation of the particular package for information on how to interact with their respective outputs.

More detailed discussion of each individual workflows provided by *metaboWorkflows* and the packages used by them can be found in their respective sections below.

### Sample Information

*metaboWorkflows* requires the of sample information (info) for the experimental run to be processed. 
This should be a tibble with the recommended column headers that include:

* _fileOrder_ - the file order in alphabetical order as returned by `list.files()`  
* _injOrder_ - the injection order of the samples during FIE-HRMS analysis
* _fileName_ - the sample file name
* _batch_ - the sample batch
* _batchBlock_ - the randomised block of the sample
* _name_ - the sample name
* _class_ - the sample class

The row orders of the info table should match the order in which the files paths are submitted to the `workflowParameters()` function.
Further columns can be added to this file to denote different class labelling.

The file paths and sample info can be loaded for the example data using the following:

```{r files,message=FALSE}
fp <- filePaths('FIE-HRMS','BdistachyonEcotypes') 
si <- runinfo('FIE-HRMS','BdistachyonEcotypes')

head(fp)
si
```

### Parameter Selection

Appropriate default parameters for a particular workflow can be retrieved using the `workflowParameters()` function to which the file paths and sample information are submitted. 
For instance, the `FIE-HRMS fingerprinting` workflow can be retrieved using the following. 

```{r getParameters,include=FALSE}
parameters <- workflowParameters('FIE-HRMS fingerprinting',fp,si,nCores = 2)
```

```{r parameters,eval=FALSE}
parameters <- workflowParameters('FIE-HRMS fingerprinting',fp,si)
parameters
```

The files paths of sample information can be returned or set from a give set of workflow parameters using the `files()` and `info()` methods.

```{r parameterFilePaths,eval=FALSE}
files(parameters)
info(parameters)
```

The parameters can be altered for a given workflow section using the following functions:

* `parametersProcessing()`
* `parametersAnalysis()`
* `parametersAnnotatation()`

For instance the processing parameters could be returned using:

```{r processingParameters}
parametersProcessing(parameters)
```

Then the scan numbers for spectral binning could be altered using:

```{r bin,eval=FALSE}
parametersProcessing(parameters) <- binParameters(scans = 5:11)
```

### Workflow

Executing a workflow is simple using the `workflow()` function.

```{r workflow, eval=FALSE}
analysis <- workflow(parameters)
```

The following functions can be used for extracting the workflow results for each of the relevant sections:

* `resultsParameters()`
* `resultsProcessing()`
* `resultsAnalysis()`
* `resultsAnnotation()`

For instance to extract the processing results of a `Workflow` object:

```{r processingResults,eval=FALSE}
resultsProcessing(analysis)
```

Alternatively the processed and pre-treated data matrices and sample info can be retrieved using:

* `processedInfo()`
* `processedData()`
* `preTreatedInfo()`
* `preTreatedData()`

#### Check Points

Some workflows can include check points where a workflow is intermediately stopped.
Reasons for this could include a step that requires a manual curation of data quality such as identifying outlier samples. 

Breaks can be removed by specifying the `breaks` argument when the workflow parmeters are detected.

```{r breaks,eval=FALSE}
parameters <- workflowParameters('FIE-HRMS fingerprinting',fp,si,breaks = F)
```

A workflow can easily be restarted after a break point using the following.

```{r continueWorkflow, eval=FALSE}
analysis <- restartWorkflow(analysis)
```

Alternatively a checkpoint can be skipped simply by piping the output form the initial `workflow()` call directly into `restartWorkflow()` as shown below.

```{r completeWorkflow, eval=FALSE}
analysis <- workflow(files,info,parameters) %>%
  restartWorkflow()
```

#### Failure

There are likely to be times where a workflow will fail mid-analysis, potentially as a result of an unsuitably set parameter.
The included workflows are broken up into flag points to allow failures to be isolated and data processed from previous, potentially time consuming steps, to be returned.
The point of failure will also be printed to the console if an error occurs.
This allows the error to potentially be fixed then the workflow to be restarted from the point of failure using:

```{r restartWorkflow, eval=FALSE}
analysis <- restartWorkflow(analysis)
```

### Flags

Each workflow is made up of sections (flags) each with its own function. 
The flags for a given workflow can be retrieved using the following:

```{r, showFlagsExample,eval=FALSE}
wp <- workflowParameters('FIE-HRMS fingerprinting',fp,si)
flags(wp)
```

```{r, showFlags,include=FALSE}
wp <- workflowParameters('FIE-HRMS fingerprinting',fp,si,nCores = 2)
```

Workflows can be customised using these flags.
Flags can be removed or added using `flags()`. For instance the following will remove the flags related to MF assignment:

```{r removeFlags}
flags(wp) <- flags(wp)[-(4:5)]
flags(wp)
```

### Plotting

A number of plotting methods are available for processed and pre-treated data that are extensions of the functions found within the `binneR`, `profilePro` and `metabolyseR` packages.
These functions include:

* `plotTIC()`
* `plotRSD()`
* `plotPCA()`
* `plotLDA()`
* `plotUnsupervisedRF()`
* `plotSupervisedRF()`
