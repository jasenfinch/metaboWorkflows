---
title: "metaboWorkflows"
author: "Jasen Finch"
output: 
  prettydoc::html_pretty:
    toc: true
    highlight: github
    theme: tactile
vignette: >
  %\VignetteIndexEntry{Introduction to metaboWorkflows}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r example-data-check, include=FALSE}
available_datasets <- metaboData::availableDataSets()

if (available_datasets$status[available_datasets$technique == 'FIE-HRMS' & 
                              available_datasets$`data set` == 'BdistachyonEcotypes'] != 'available'){
  metaboData::downloadDataSet('FIE-HRMS','BdistachyonEcotypes',ask = FALSE)
}
```

## Introduction

Metabolomics encompasses a wide range of techniques that includes mass spectrometry based fingerprinting and profiling.
The analysis of this data requires a number of steps that includes spectral processing, data pre-treatment, quality control, data mining and visualisation in order to extract relevant biological information.
The goal of `metaboWorkflows` is to provide project directory templates for a range of mass spectrometry based metabolomic techniques.
The generated project template directories can then be easily extended by the user to meet the needs of particular analysis goals.

These project templates utilise a number of tools to promote efficient and reproducible analysis, agnostic of the actual analysis R code.
These tools include:

* [targets](https://docs.ropensci.org/targets/) - an R focused pipeline toolkit for efficiently maintaining reproducible analysis workflows.
* [renv](https://rstudio.github.io/renv/) - an R package for project-local R package dependency management for maintaining reproducible R package environments.
* [git](https://git-scm.com/) - a widely used, open-source distributed version control system.
* [docker](https://www.docker.com/) - enables the containerization of operating system (OS) level environments. This can be used to define reproducible OS environments in which a workflow analysis can be performed.

While the use of most of these tools is optional but highly encouraged, it is recommended for the user to at least be familiar with the basic use of `targets` based pipelines outlined [here](https://books.ropensci.org/targets/walkthrough.html).

There are three steps in using `metaboWorkflows` to generate a workflow project template directory. 
These are as follows:

* **input** - define the input data source of the workflow
* **define** - define the workflow steps based on the metabolomic technique and project directory structure
* **generate** - generate the workflow project directory

This introduction will outline each of these steps, provide an overview of an example workflow project directory and how to execute one of these workflows.

To begin, firstly load the package:

```{r setup}
library(metaboWorkflows)
```

## Workflow input

Prior to defining a workflow, the user needs to know what sort of input type the workflow will use.
`metaboWorkflows` currently supports two types: remote data obtained through the use of a [`grover`](https://jasenfinch.github.io/grover/) RESTful web API or through providing a vector of .mzML file paths and a [`tibble`](https://tibble.tidyverse.org/) of sample information.

### `grover` API input

The [`grover`](https://jasenfinch.github.io/grover/) R package provides a framework for hosting RESTful web APIs for remote access and conversion of raw metabolomics data to the .mzML format.

This type of input can be declared by providing the host information of the [`grover`](https://jasenfinch.github.io/grover/) API to the `inputGrover` function.
Below shows an example for a fictitious [`grover`](https://jasenfinch.github.io/grover/) API host.

```{r grover-input}
workflow_input <- inputGrover(instrument = 'An_instrument',
                              directory = 'Experiment_directory',
                              host = 'a.grover.host',
                              port = 80,
                              auth = '1234')
```

```{r print-grover-input}
print(workflow_input)
```

### File path input

If the raw mass spectrometry .mzML format data files are locally available for a sample set, their file paths and a [`tibble`](https://tibble.tidyverse.org/) of the sample information can be provided for workflow input.

Below shows an example file path input for the FIE-HRMS fingerprinting data set of *Brachypodium distachyon* ecotype comparisons available in the [`metaboData`](https://aberhrml.github.io/metaboData/) package.

```{r file-path-input}
file_paths <- metaboData::filePaths('FIE-HRMS','BdistachyonEcotypes')
sample_information <- metaboData::runinfo('FIE-HRMS','BdistachyonEcotypes')

workflow_input <- inputFilePath(file_paths,sample_information)
```

```{r print-file-path-input}
print(workflow_input)
```

This example input will be used throughout the rest of this introduction.

## Define a workflow

Workflow definition is simple and requires the input definition outlined in the previous section, the name of the metabolomic technique and the project name.

To return the currently available metabolomic workflow templates, use:

```{r available-workflows}
availableWorkflows()
```

This example will use the `FIE-HRMS fingerprinting` template and the project will be named `Example project`. 

```{r workflow-definition}
workflow_definition <- defineWorkflow(
  input = workflow_input,
  workflow = 'FIE-HRMS fingerprinting',
  project_name = 'Example project'
)
```

Further project template options can also be specified at this point such as the output directory path or the use of `renv` for R package management. 
See `?defineWorkflow` for more details.
Printing the resulting workflow definition will provide information about the defined workflow.

```{r print-workflow}
print(workflow_definition)
```

As shown above, this workflow definition contains `r targets(workflow_definition) %>% unlist(recursive = TRUE) %>% length()` targets.
These targets are the individual steps in the analysis pipeline.
The full workflow graph, showing the relationships between these targets, can be plotted as shown below:

```{r glimpse-workflow}
glimpse(workflow_definition)
```

The package also contains functionality for modifying and extending the targets available in the workflow templates.
This is outlined in the [Workflow customisation and extension](customisation.html) vignette.

## Generate a workflow project directory

The final step is the generation of the project directory for the defined workflow.

```{r generate-workflow,eval=FALSE}
generateWorkflow(workflow_definition)
```

This will then generate the project directory at the specified directory path.
The additional `start` argument can be used to automatically open the project directory in the RStudio IDE after project generation.

## The project directory

Below shows an overview of the generated `Example project` project directory:

```
Example_project/
├── Dockerfile
├── Example_project.Rproj
├── R
│   ├── functions
│   └── utils.R
├── README.md
├── _targets.R
├── data
│   ├── file_paths.txt
│   └── runinfo.csv
├── exports
├── misc
├── renv
│   ├── activate.R
│   ├── library
│   ├── local
│   ├── settings.dcf
│   └── staging
├── renv.lock
├── report
│   └── report.Rmd
└── run.R
```

The presence of some of these components will be dependent on the defined project options and the input type that was selected in the workflow definition.
Here, a brief overview of some of the important components will be given.

`Dockerfile` - This can be used build a suitable docker image from which the workflow can be executed within a containerised OS environment.

`R/functions` - Scripts containing additional functions can be placed here.

`R/utils.R` - This contains any code related to loading packages.

`_targets.R` - This script contains the formal definition of the workflow with the analysis code for each of the target components of the workflow. 
See [here](https://books.ropensci.org/targets/walkthrough.html#target-script-file) for more information about the this file.

`data` - Where workflow input data is stored. The contents of this directory will differ depending on whether a grover API or file path input type has been selected.

`exports` - Any outputs from the workflow will be directed here including the HTML output and any .csv data table outputs.

`misc` - Any miscellaneous scripts and files can be placed here.

`renv.lock` - A lock file used by the `renv` package to capture the state of the R package library used in the project.

`report/report.Rmd` - An R Markdown report for summarising the workflow results. 
It's output will be saved in `exports`.

`run.R` - An script that can be used to execute the workflow. See the section below for more information.

## Executing an analysis workflow

There are a number of ways in which the workflow can be executed after the project directory has been generated.
The targets package provides some information on this topic [here](https://books.ropensci.org/targets/walkthrough.html#run-the-pipeline).

The recommended method is through opening the project in the [RStudio IDE](https://www.rstudio.com/) and running the workflow as a job using the [`rstudioapi`](https://rstudio.github.io/rstudioapi/) package and `run.R` script as follows:

```{r execute, eval=FALSE}
rstudioapi::jobRunScript('run.R')
```
